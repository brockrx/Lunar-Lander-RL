{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d691030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import concurrent.futures\n",
    "import time\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab017002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(\n",
    "        self, \n",
    "        alpha = 0.001,\n",
    "        layers = [256, 256],\n",
    "        input_dim = 8,\n",
    "        output_dim = 4,\n",
    "        gamma = 0.9,\n",
    "        epsilon = 0.2\n",
    "        ):\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.layers = layers\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.score_list = None\n",
    "        self.env = gym.make(\"LunarLander-v2\")\n",
    "        \n",
    "        self.initialize_policy()\n",
    "        \n",
    "    def initialize_policy(self):\n",
    "        self.policy = NeuralNetwork(self.input_dim, self.output_dim, self.layers, self.alpha)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.SGD(self.policy.parameters(), lr=self.alpha)\n",
    "    \n",
    "    def train(self, iterations, episodes):\n",
    "        if self.score_list is None:\n",
    "            self.score_list = []\n",
    "        previous_weights = self.policy.get_weights().flatten()\n",
    "        for i in range(iterations):\n",
    "            states = []\n",
    "            returns = np.empty((1))\n",
    "            iteration_scores = []\n",
    "            for e in range(episodes):\n",
    "                s = self.env.reset()\n",
    "                temp_states = []\n",
    "                rewards = []\n",
    "                score = 0\n",
    "                done = False\n",
    "                while not done:\n",
    "                    temp_states.append(s)\n",
    "                    a = self.get_action(s)\n",
    "                    s, r, done, _ = self.env.step(a)\n",
    "                    rewards.append(r)\n",
    "                    score += r\n",
    "                iteration_scores.append(score)\n",
    "                states += temp_states\n",
    "                returns = np.concatenate((returns, self.compute_returns(rewards)))\n",
    "            iteration_score_mean = np.mean(iteration_scores)\n",
    "            iteration_score_std = np.std(iteration_scores)\n",
    "            print(f'Iteration {i+1}: {np.mean(iteration_score_mean)} +/- {iteration_score_std}')\n",
    "            self.update(np.array(states), returns)\n",
    "            current_weights = self.policy.get_weights().flatten()\n",
    "            delta = (np.sum((current_weights - previous_weights)**2)**(1/2))\n",
    "            print(f'Weight change: {delta}')\n",
    "            mean_weight_magnitude = np.mean(np.abs(current_weights))\n",
    "            #print(f'Weight Magnitude (mean): {mean_weight_magnitude}')\n",
    "        \n",
    "            \n",
    "    def get_action(self, state):\n",
    "        random_number = random.random()\n",
    "        if random_number >= self.epsilon:\n",
    "            with torch.no_grad():\n",
    "                action = torch.argmax(self.policy.forward(np.expand_dims(state, 0))[0,:]).item()\n",
    "        else:\n",
    "            action = random.randint(0, 3)\n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def compute_returns(self, rewards):\n",
    "        returns = np.zeros(len(rewards))\n",
    "        return_val = 0\n",
    "        for i, reward in enumerate(reversed(rewards)):\n",
    "            return_val = reward + self.gamma*return_val\n",
    "            returns[-(i+1)] = return_val\n",
    "        return returns\n",
    "    \n",
    "    \n",
    "    def custom_loss(self, action_probs, returns):\n",
    "        actions = torch.max(action_probs, 1, keepdim=True)[0]\n",
    "        log_actions = torch.log(actions)\n",
    "        loss = torch.mean(log_actions * returns)\n",
    "        return loss\n",
    "\n",
    "        \n",
    "    def update(self, states, returns):\n",
    "        \n",
    "        action_probs = self.policy.forward(states, train=True)\n",
    "        \n",
    "        # Perform gradient descent step\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.custom_loss(action_probs, torch.tensor(returns*-1))\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        delta = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3197638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, layer_dims, alpha):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.layer_dims = layer_dims\n",
    "        self.alpha = alpha\n",
    "        current_dim = input_dim\n",
    "        \n",
    "        self.create_model()\n",
    "        \n",
    "        \n",
    "    def create_model(self):\n",
    "        if len(self.layer_dims) == 0:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.input_dim, self.output_dim),\n",
    "                nn.Softmax()\n",
    "            )\n",
    "        \n",
    "        elif len(self.layer_dims) == 1:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.input_dim, self.layer_dims[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(self.layer_dims[0]),\n",
    "                nn.Linear(self.layer_dims[0], self.output_dim),\n",
    "                nn.Softmax(dim=1)\n",
    "            )\n",
    "        elif len(self.layer_dims) == 2:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.input_dim, self.layer_dims[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(self.layer_dims[0]),\n",
    "                nn.Linear(self.layer_dims[0], self.layer_dims[1]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(self.layer_dims[1]),\n",
    "                nn.Linear(self.layer_dims[1], self.output_dim),\n",
    "                nn.Softmax(dim=1)\n",
    "            )\n",
    "        elif len(self.layer_dims) == 3:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.input_dim, self.layer_dims[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(self.layer_dims[0]),\n",
    "                nn.Linear(self.layer_dims[0], self.layer_dims[1]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(self.layer_dims[1]),\n",
    "                nn.Linear(self.layer_dims[1], self.layer_dims[2]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(self.layer_dims[2]),\n",
    "                nn.Linear(self.layer_dims[2], self.output_dim),\n",
    "                nn.Softmax(dim=1)\n",
    "            )\n",
    "        elif len(self.layer_dims) == 4:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(self.input_dim, self.layer_dims[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(self.layer_dims[0]),\n",
    "                nn.Linear(self.layer_dims[0], self.layer_dims[1]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(self.layer_dims[1]),\n",
    "                nn.Linear(self.layer_dims[1], self.layer_dims[2]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(self.layer_dims[2]),\n",
    "                nn.Linear(self.layer_dims[2], self.layer_dims[3]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(self.layer_dims[3]),\n",
    "                nn.Linear(self.layer_dims[3], self.output_dim),\n",
    "                nn.Softmax(dim=1)\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x, train=False):\n",
    "        if type(x) is not torch.Tensor:\n",
    "            x = torch.tensor(x)\n",
    "        if not train:\n",
    "            self.model.eval()\n",
    "        else:\n",
    "            self.model.train()\n",
    "        out = self.model(x.float())\n",
    "        return out\n",
    "    \n",
    "    def get_weights(self):\n",
    "        weights = []\n",
    "        for param in self.parameters():\n",
    "            weights.append(param.detach().numpy().flatten())\n",
    "        return np.concatenate(weights)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a02219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(layers=[64, 64, 64], alpha=0.00001, gamma=0.99, epsilon=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d03dc9af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: -137.79608493066502 +/- 43.56486477254089\n",
      "Weight change: 0.00188188845487748\n",
      "Iteration 2: -128.5542502859878 +/- 36.51451626064602\n",
      "Weight change: 0.0036189079171575116\n",
      "Iteration 3: -126.62397702427462 +/- 42.45432953789809\n",
      "Weight change: 0.005302916648469262\n",
      "Iteration 4: -132.7613783818465 +/- 41.56189733572737\n",
      "Weight change: 0.0068950122815384365\n",
      "Iteration 5: -124.9286571904864 +/- 44.66894206622537\n",
      "Weight change: 0.008449125601949022\n",
      "Iteration 6: -137.65792061024848 +/- 44.230601828023495\n",
      "Weight change: 0.010025439551364309\n",
      "Iteration 7: -131.37654385065008 +/- 40.139693005549546\n",
      "Weight change: 0.01177536308222397\n",
      "Iteration 8: -132.35587757818058 +/- 40.3469354851024\n",
      "Weight change: 0.01322420804906784\n",
      "Iteration 9: -135.07787159572888 +/- 36.277051960891754\n",
      "Weight change: 0.014962442380122521\n",
      "Iteration 10: -129.32088805315436 +/- 44.23744134731829\n",
      "Weight change: 0.016615557556858923\n",
      "Iteration 11: -112.28800794277755 +/- 45.73130441678851\n",
      "Weight change: 0.017950335946249972\n",
      "Iteration 12: -149.8215864037302 +/- 89.70486692118163\n",
      "Weight change: 0.018996424831832743\n",
      "Iteration 13: -187.65881361733824 +/- 117.59642281519645\n",
      "Weight change: 0.02030234854034769\n",
      "Iteration 14: -235.7725209128766 +/- 139.3202124314391\n",
      "Weight change: 0.021688432368889142\n",
      "Iteration 15: -249.16827050673388 +/- 140.58608601328922\n",
      "Weight change: 0.023036074633320493\n",
      "Iteration 16: -266.6289489893056 +/- 144.26421856626885\n",
      "Weight change: 0.024668161581362494\n",
      "Iteration 17: -290.23573595355424 +/- 157.54019919681045\n",
      "Weight change: 0.026351315745793892\n",
      "Iteration 18: -294.78622389319355 +/- 148.94885413453568\n",
      "Weight change: 0.028009360056516386\n",
      "Iteration 19: -293.9472619773596 +/- 148.33126257801848\n",
      "Weight change: 0.029969172648397113\n",
      "Iteration 20: -322.5165503837861 +/- 143.7822737060918\n",
      "Weight change: 0.03230722404148298\n",
      "Iteration 21: -315.88078985839456 +/- 162.4469081192457\n",
      "Weight change: 0.0348472058609506\n",
      "Iteration 22: -327.5770555524987 +/- 137.22740908813455\n",
      "Weight change: 0.037442030779585356\n",
      "Iteration 23: -329.35531847603454 +/- 152.02133086543733\n",
      "Weight change: 0.03964642451489595\n",
      "Iteration 24: -339.80654914488184 +/- 137.71788577358325\n",
      "Weight change: 0.042615978558610754\n",
      "Iteration 25: -380.7846950960062 +/- 150.82814540334093\n",
      "Weight change: 0.046031672289647066\n",
      "Iteration 26: -416.47666602193016 +/- 125.82486042275681\n",
      "Weight change: 0.04986105328553275\n",
      "Iteration 27: -433.19685318334916 +/- 123.71668969020261\n",
      "Weight change: 0.05288872382946358\n",
      "Iteration 28: -439.14085268634824 +/- 116.49769313103715\n",
      "Weight change: 0.05587921057161239\n",
      "Iteration 29: -451.28159175383195 +/- 110.94819236662865\n",
      "Weight change: 0.05852917848471252\n",
      "Iteration 30: -463.63838586669686 +/- 110.73592398764823\n",
      "Weight change: 0.060933140375615036\n",
      "Iteration 31: -469.282665849979 +/- 112.75762333079864\n",
      "Weight change: 0.06250603467894471\n",
      "Iteration 32: -484.92120576146823 +/- 104.42715034715793\n",
      "Weight change: 0.06463311811956106\n",
      "Iteration 33: -478.1590520667852 +/- 125.1399480107812\n",
      "Weight change: 0.06629640596431986\n",
      "Iteration 34: -502.99875064836726 +/- 99.252320247477\n",
      "Weight change: 0.06806641883795252\n",
      "Iteration 35: -488.85819542585705 +/- 112.215583320746\n",
      "Weight change: 0.06984978987886437\n",
      "Iteration 36: -477.5665491210014 +/- 118.54462736250699\n",
      "Weight change: 0.07157741651452955\n",
      "Iteration 37: -477.66141730286984 +/- 136.17780337045374\n",
      "Weight change: 0.07411507530556224\n",
      "Iteration 38: -477.18963274874625 +/- 113.12568106465385\n",
      "Weight change: 0.07633370851009548\n",
      "Iteration 39: -481.77625552475087 +/- 126.01893806513843\n",
      "Weight change: 0.0784287983220479\n",
      "Iteration 40: -496.7494103748669 +/- 122.80021332545013\n",
      "Weight change: 0.08045393288866658\n",
      "Iteration 41: -503.60375529277405 +/- 115.88002726210067\n",
      "Weight change: 0.08291860162252025\n",
      "Iteration 42: -470.7430518025333 +/- 126.33742579221502\n",
      "Weight change: 0.08487851430874518\n",
      "Iteration 43: -498.49726459733654 +/- 114.18245542692269\n",
      "Weight change: 0.08738479491360993\n",
      "Iteration 44: -504.63423576717753 +/- 121.27526245415979\n",
      "Weight change: 0.089775899476703\n",
      "Iteration 45: -471.3144817713934 +/- 112.11523227565796\n",
      "Weight change: 0.09123359496783896\n",
      "Iteration 46: -475.10488364728775 +/- 123.18712428916584\n",
      "Weight change: 0.0927843137690073\n",
      "Iteration 47: -471.84530737385353 +/- 131.88312795469082\n",
      "Weight change: 0.0945597881399765\n",
      "Iteration 48: -471.5040621375431 +/- 103.2459599608687\n",
      "Weight change: 0.09616377961447742\n",
      "Iteration 49: -477.9621270454291 +/- 116.7907642201398\n",
      "Weight change: 0.09792126934752302\n",
      "Iteration 50: -466.7842502797789 +/- 125.23052416667802\n",
      "Weight change: 0.09941109388674393\n",
      "Iteration 51: -478.078465982206 +/- 116.04245075661645\n",
      "Weight change: 0.10142173548929637\n",
      "Iteration 52: -488.30091482715267 +/- 110.50785889456334\n",
      "Weight change: 0.10272753515065196\n",
      "Iteration 53: -474.53542711582014 +/- 111.53490089039167\n",
      "Weight change: 0.10436292478530008\n",
      "Iteration 54: -463.46128614145647 +/- 105.21772782147755\n",
      "Weight change: 0.10544627886265254\n",
      "Iteration 55: -451.70805544913026 +/- 104.6838186231229\n",
      "Weight change: 0.10630259877334898\n",
      "Iteration 56: -465.50999418350926 +/- 120.07318118183362\n",
      "Weight change: 0.10807676959542488\n",
      "Iteration 57: -434.3612827134817 +/- 113.29036722242347\n",
      "Weight change: 0.10926638898578306\n",
      "Iteration 58: -436.11909708031146 +/- 108.606677311411\n",
      "Weight change: 0.11016401878990723\n",
      "Iteration 59: -425.1164206699547 +/- 112.38774114330171\n",
      "Weight change: 0.1113404551587858\n",
      "Iteration 60: -420.9255219055908 +/- 113.87759592766339\n",
      "Weight change: 0.11240068147757525\n",
      "Iteration 61: -417.7510524671054 +/- 112.81907868321785\n",
      "Weight change: 0.11360075715187937\n",
      "Iteration 62: -429.65182581672656 +/- 109.38200368342163\n",
      "Weight change: 0.11410751401691423\n",
      "Iteration 63: -389.73453348804253 +/- 122.43450391549767\n",
      "Weight change: 0.11497369878170084\n",
      "Iteration 64: -392.57760833455006 +/- 126.83906922627273\n",
      "Weight change: 0.11576546307837055\n",
      "Iteration 65: -364.4153372943761 +/- 122.37768823411629\n",
      "Weight change: 0.11684189936515718\n",
      "Iteration 66: -379.3791841992961 +/- 132.42143148827918\n",
      "Weight change: 0.11774170085767688\n",
      "Iteration 67: -382.34252278266536 +/- 119.11840470871782\n",
      "Weight change: 0.11894290182492653\n",
      "Iteration 68: -391.29555746685617 +/- 113.5620873506586\n",
      "Weight change: 0.1201539603599296\n",
      "Iteration 69: -373.6684082933869 +/- 126.37479927341573\n",
      "Weight change: 0.12125485608979998\n",
      "Iteration 70: -384.4191500373422 +/- 114.65448280540637\n",
      "Weight change: 0.12225665556210144\n",
      "Iteration 71: -368.74961882909633 +/- 112.485828232467\n",
      "Weight change: 0.12267064675194946\n",
      "Iteration 72: -364.7761351488076 +/- 118.13032625362791\n",
      "Weight change: 0.1238686278736743\n",
      "Iteration 73: -353.25559474716323 +/- 114.13007468582306\n",
      "Weight change: 0.12480272431836893\n",
      "Iteration 74: -365.0107761479195 +/- 139.2018557600859\n",
      "Weight change: 0.1260793621334886\n",
      "Iteration 75: -320.1459544387683 +/- 118.55042427005465\n",
      "Weight change: 0.12737248921376465\n",
      "Iteration 76: -338.10818178205693 +/- 118.72361106676763\n",
      "Weight change: 0.12877379461423039\n",
      "Iteration 77: -347.45598305336347 +/- 133.42693034828258\n",
      "Weight change: 0.12987212803999865\n",
      "Iteration 78: -328.75917319753773 +/- 121.48042045546555\n",
      "Weight change: 0.130575584026289\n",
      "Iteration 79: -306.2909637118804 +/- 115.6368629417124\n",
      "Weight change: 0.1314497696119439\n",
      "Iteration 80: -296.2192719153146 +/- 122.13676716244697\n",
      "Weight change: 0.13265884149758675\n",
      "Iteration 81: -298.4544591884967 +/- 128.01223238629777\n",
      "Weight change: 0.1336906795328701\n",
      "Iteration 82: -296.4032212541953 +/- 116.32212668010759\n",
      "Weight change: 0.13397676985707543\n",
      "Iteration 83: -285.77451787474956 +/- 129.49103213343733\n",
      "Weight change: 0.1352206991587242\n",
      "Iteration 84: -295.88252546193536 +/- 125.34445688608521\n",
      "Weight change: 0.13625536455302678\n",
      "Iteration 85: -290.54738217230545 +/- 117.23028257222931\n",
      "Weight change: 0.1373422167131507\n",
      "Iteration 86: -296.21145467188137 +/- 119.54263510596714\n",
      "Weight change: 0.13838386176799147\n",
      "Iteration 87: -270.3888753946714 +/- 118.34417154555688\n",
      "Weight change: 0.13950103369581082\n",
      "Iteration 88: -272.9769451041411 +/- 118.94010158002396\n",
      "Weight change: 0.14044754434732526\n",
      "Iteration 89: -292.5468396233479 +/- 124.5342217257301\n",
      "Weight change: 0.14162997256755394\n",
      "Iteration 90: -280.33080755727843 +/- 117.88050216925711\n",
      "Weight change: 0.14237648278754517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 91: -277.39065062192674 +/- 120.56218163355027\n",
      "Weight change: 0.14309748028960004\n",
      "Iteration 92: -261.4643882243713 +/- 125.82006847015799\n",
      "Weight change: 0.14395596737810495\n",
      "Iteration 93: -283.1574876663189 +/- 124.92121380675444\n",
      "Weight change: 0.14487698160401083\n",
      "Iteration 94: -267.4499437267285 +/- 125.89927575495412\n",
      "Weight change: 0.14587089503297487\n",
      "Iteration 95: -280.2036519380629 +/- 126.74941202539635\n",
      "Weight change: 0.14652150637178585\n",
      "Iteration 96: -282.06152955715385 +/- 136.69716540840957\n",
      "Weight change: 0.14745920066568538\n",
      "Iteration 97: -271.9877397439667 +/- 126.8113999685332\n",
      "Weight change: 0.14833549081268296\n",
      "Iteration 98: -255.5866325293272 +/- 117.54884353840535\n",
      "Weight change: 0.14895849650269577\n",
      "Iteration 99: -281.4100585994205 +/- 131.63408785531786\n",
      "Weight change: 0.1498356462640198\n",
      "Iteration 100: -277.1747658466185 +/- 145.06735462768108\n",
      "Weight change: 0.15018332424859476\n"
     ]
    }
   ],
   "source": [
    "agent.train(100, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f1180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
